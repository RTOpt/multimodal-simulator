import pandas as pd
import numpy as np
import os
import json
import ast
import csv

def generate_duration_test_instance(name : str,
                                    date: str,
                                    start_time : int = 20000,
                                    duration : int = 7200,
                                    base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'fixed_line', 'gtfs'),
                                    route_ids = []):
    """
    Generate a test instance for a given date and duration.
    The test instance is generated by filtering the GTFS files based on the selected start_time and duration.
    The connections are then filtered based on the selected stop_ids, and the requests are filtered based on the selected trip_ids.

    Inputs:
    - date: the date for which to generate the test instance (format: "YYYY-MM-DD")
    - start_time: the start time (in seconds from midnight) after which to consider trips
    - duration: the duration of the test instance in seconds
    - base_path: the base path where the GTFS files are stored
    """

    # Filter GTFS files based on start_time and duration
    filter_gtfs_files_duration(start_time, duration, base_path, date, name)

    # Filter connections based on selected stop_ids
    output_path = os.path.join(base_path, f"{date}-{name}")
    selected_stop_ids = pd.read_csv(os.path.join(output_path, "stops.txt"))['stop_id'].unique()
    input_path = os.path.join(base_path, date)
    filter_connections(input_path, output_path, selected_stop_ids)

    # filter requests based on the selected trip_ids and only keep trip_ids that are associated to a route_id in route_ids
    selected_trip_ids = pd.read_csv(os.path.join(output_path, "trips.txt"))
    selected_trip_ids = selected_trip_ids[selected_trip_ids['route_id'].isin(route_ids)]['trip_id'].unique()
    all_trip_ids = pd.read_csv(os.path.join(output_path, "trips.txt"))['trip_id'].unique()
    trip_ids_to_keep = filter_requests(date, selected_trip_ids, name, all_trip_ids, base_path)

    #filter the trip_ids in the os.path.join(output_path, "trips.txt")
    trips_df = pd.read_csv(os.path.join(output_path, "trips.txt"))
    filtered_trips_df = trips_df[trips_df['route_id'].isin(route_ids)]
    # concatenate the trip_ids to keep
    trip_ids_to_keep = list(trip_ids_to_keep)
    trip_ids_to_keep += list(filtered_trips_df['trip_id'].unique())
    trips_df = trips_df[trips_df['trip_id'].isin(trip_ids_to_keep)]
    trips_df.to_csv(os.path.join(output_path, "trips.txt"), index=False)

    #filter the stop_times_upgrade.txt
    stop_times_df = pd.read_csv(os.path.join(output_path, "stop_times_upgrade.txt"))
    stop_times_df = stop_times_df[stop_times_df['trip_id'].isin(trip_ids_to_keep)]
    stop_times_df.to_csv(os.path.join(output_path, "stop_times_upgrade.txt"), index=False)

    #filter the stops.txt
    selected_stop_ids = stop_times_df['stop_id'].unique()
    stops_df = pd.read_csv(os.path.join(output_path, "stops.txt"))
    final_stops_df = stops_df[stops_df['stop_id'].isin(selected_stop_ids)]
    final_stops_df.to_csv(os.path.join(output_path, "stops.txt"), index=False)

    print("Extraction complete. Output files generated for test instance with duration")

def filter_gtfs_files_duration(start_time : int,
                               duration : int,
                               base_path : str,
                               date,
                               name : str = "TestInstanceDuration"):
    """
    Filter GTFS files based on the selected start_time and duration.
    The filtered files are saved in a new directory named "{date}-TestInstanceDuration"

    Inputs:
    - start_time: the start time (in seconds from midnight) after which to consider trips
    - duration: the duration of the test instance in seconds
    - base_path: the base path where the GTFS files are stored
    - date: the date for which to generate the test instance (format: "YYYY-MM-DD")
    """
    # Load input files
    input_path = os.path.join(base_path, date)
    stop_times_path = os.path.join(input_path, "stop_times_upgrade.txt")
    trips_path = os.path.join(input_path, "trips.txt")
    stops_path = os.path.join(input_path, "stops.txt")

    #Load GTFS data into dataframes
    stop_times_df = pd.read_csv(stop_times_path)
    trips_df = pd.read_csv(trips_path)
    stops_df = pd.read_csv(stops_path)

    # Step 1: Filter trips that have planned_departure_time_from_origin after start_time and before start_time+duration
    # Check in stop_times_upgrade.txt for rows that have planned_departure_time_from_origin after start_time and before start_time+duration
    filtered_stop_times = stop_times_df[(stop_times_df['arrival_time'] >= start_time) & (stop_times_df['arrival_time'] <= start_time + duration)]
    # Get the unique trip_ids from the filtered stop times
    selected_trips = filtered_stop_times['trip_id'].unique()
    # Filter trips.txt to keep only the selected trips
    filtered_trips_df = trips_df[trips_df['trip_id'].isin(selected_trips)]

    # Step 2: Filter stop_times_upgrade.txt to keep only stop times for the selected trips
    final_stop_times_df = stop_times_df[stop_times_df['trip_id'].isin(filtered_trips_df['trip_id'])]

    # Step 3: Get the unique stop_ids from the filtered stop times
    selected_stop_ids = final_stop_times_df['stop_id'].unique()

    # Step 4: Filter stops.txt to keep only the stops in the selected trips
    final_stops_df = stops_df[stops_df['stop_id'].isin(selected_stop_ids)]

    # Create output directory
    output_path = os.path.join(base_path, f"{date}-{name}")
    os.makedirs(output_path, exist_ok = True)

    # Save output files
    filtered_trips_df.to_csv(os.path.join(output_path, "trips.txt"), index=False)
    final_stop_times_df.to_csv(os.path.join(output_path, "stop_times_upgrade.txt"), index=False)
    final_stops_df.to_csv(os.path.join(output_path, "stops.txt"), index=False)

def filter_connections(input_path, output_path, selected_stop_ids):
    """
    Filter available_connections.json based on the selected stop_ids.
    The filtered connections are saved in a new available_connections.json file.

    Inputs:
    - input_path: the path to the input directory containing available_connections.json
    - output_path: the path to the output directory where the new available_connections.json will be saved
    - selected_stop_ids: a list of selected stop_ids to keep in the available connections
    """

    available_connections_path = os.path.join(input_path, "available_connections.json")

    # Load available_connections.json and filter based on selected stop_ids
    with open(available_connections_path, 'r') as f:
        available_connections = json.load(f)

    filtered_connections = []
    for connection in available_connections:
        # Keep only the stops that are in the selected stop_ids
        filtered_connection = [stop_id for stop_id in connection if stop_id in selected_stop_ids]
        # Add the filtered connection if it still has more than one stop
        if len(filtered_connection) > 1:
            filtered_connections.append(filtered_connection)

    # Save the new available_connections.json
    output_connections_path = os.path.join(output_path, "available_connections.json")
    with open(output_connections_path, 'w') as f:
        json.dump(filtered_connections, f, indent=4)

def filter_requests(date, selected_trip_ids, name, all_trip_ids =[], base_path=os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'fixed_line', 'gtfs')):
    """
    Filter requests.csv based on the selected bus trip_ids.
    The filtered requests are saved in a new filtered_requests.csv file.

    Inputs:
    - date: the date for which to generate the test instance (format: "YYYY-MM-DD")
    - selected_trip_ids: a list of selected bus trip_ids to keep in the requests
    - name: the name of the test instance
    - base_path: the base path where the GTFS files are stored
    """
    # Load input files
    input_path = os.path.join(base_path, date)
    requests_path = os.path.join(input_path, "requests.csv")

    # Load requests.csv into dataframe
    requests_df = pd.read_csv(requests_path, sep=';')

    # Step 1: Filter requests that have at least one leg with a selected trip_id
    filtered_requests = []
    for _, row in requests_df.iterrows():
        legs = ast.literal_eval(row['legs'])  # Convert string representation of list to actual list
        if len(all_trip_ids) == 0:
            filtered_legs = [leg for leg in legs if leg[2] in selected_trip_ids]
        else: 
            is_allowed = len([leg for leg in legs if leg[2] in selected_trip_ids]) > 0
            if is_allowed == False:
                continue
            filtered_legs = [leg for leg in legs if leg[2] in all_trip_ids]
        
        # If there is at least one leg with a selected trip_id, update the request
        if len(filtered_legs)>0:
            if len(filtered_legs) == len(legs):
                # Keep the request as is if all legs are selected
                filtered_requests.append(row)
            elif len(filtered_legs) == 1:
                # Update the request if only one leg is kept
                row['origin'] = filtered_legs[0][0]
                row['destination'] = filtered_legs[0][1]
                row['legs'] = str([filtered_legs[0]])
                filtered_requests.append(row)
            elif len(filtered_legs) == 2:
                # Check if the two legs are consecutive
                if filtered_legs[0][1] == filtered_legs[1][0]:
                    # Update the request to keep the consecutive legs
                    row['origin'] = filtered_legs[0][0]
                    row['destination'] = filtered_legs[1][1]
                    row['legs'] = str(filtered_legs)
                    filtered_requests.append(row)
                # Remove the request if the first and last leg were kept (not consecutive)

    # Create a new dataframe with the filtered requests
    filtered_requests_df = pd.DataFrame(filtered_requests)

    # Get all trip_ids from the filtered requests
    all_trip_ids = []
    for _, row in filtered_requests_df.iterrows():
        legs = ast.literal_eval(row['legs'])
        for leg in legs:
            all_trip_ids.append(leg[2])
    all_trip_ids = list(set(all_trip_ids))

    # Create output directory
    output_path = os.path.join(base_path, f"{date}-{name}")
    os.makedirs(output_path, exist_ok=True)

    # Save the filtered requests to a new CSV file
    output_requests_path = os.path.join(output_path, "requests.csv")
    filtered_requests_df.to_csv(output_requests_path, sep=';', index=False)

    print('All outputs generated in the folder:', output_path)
    return all_trip_ids

def get_start_time_of_bus(date, number, route_id):
    """
    Get the start time of the bus number for the route_id.
    The start time is the planned_departure_time_from_origin of the first stop_time of the trip_id.
    
    Inputs:
    - date: the date for which to generate the test instance (format: "YYYY-MM-DD")
    - number: the number of the bus in the route_id
    - route_id: the route_id of the bus

    Outputs:
    The start time.
    """
    base_path = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'fixed_line', 'gtfs')
    input_path = os.path.join(base_path, date)
    stop_times_path = os.path.join(input_path, "stop_times_upgrade.txt")
    trips_path = os.path.join(input_path, "trips.txt")
    ### Get all trip ids for the route_id
    all_trips = pd.read_csv(trips_path)
    trips = all_trips[all_trips['route_id'] == route_id]
    unique_trips = trips['trip_id'].unique()

    ### Get first times for the each trip_id
    stop_times = pd.read_csv(stop_times_path)
    start_times = []
    for trip_id in unique_trips:
        ### If the trip is in the stop_times, get the first row
        if len(stop_times[stop_times['trip_id'] == trip_id]) == 0:
            # print('There is a missing trip_id:', trip_id)
            continue
        row = stop_times[stop_times['trip_id'] == trip_id].iloc[0]
        start_times.append((trip_id, row['planned_departure_time_from_origin']))
    start_times.sort(key=lambda x: x[1])
    return start_times[number]

if __name__ == "__main__":
    dates = ["2019-11-25", "2019-11-26", "2019-11-27"]
    for date in dates:
        trip_id, start_time = get_start_time_of_bus('gtfs'+date, 1, '42O')
        route_ids = ['144E', '144O', '20E', '20O', '222E', '222O', '22E', '22O', '24E', '24O', '252E', '252O', '26E', '26O', '2E', '2O', '42E', '42O', '52E', '52O', '56E', '56O', '60E', '60O', '66E', '66O', '70E', '70O', '74E', '74O', '76E', '76O', '942E', '942O', '151S', '151N', '17S', '17N', '27S', '27N', '33S', '33N', '37S', '37N', '41S', '41N', '43S', '43N', '45S', '45N', '46S', '46N', '55S', '55N', '61S', '61N', '63S', '63N', '65S', '65N', '901S', '901N', '902S', '902N', '903S', '903N', '925S', '925N']
        duration = 21600 # 6 hours
        generate_duration_test_instance('LargeInstanceAll','gtfs'+date, start_time = start_time, duration = duration, route_ids = route_ids)  # 3 hours
    